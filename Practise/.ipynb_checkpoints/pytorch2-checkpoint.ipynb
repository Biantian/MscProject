{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial 01\n",
    "Divide train set and test set. View data. Check label's percentage in total.\n",
    "\n",
    "## 1. Check library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download and divide dataset in one line.\n",
    "\n",
    "> \"\" -> Local dataset address.Torch will download MNIST dataset to \"address\"\n",
    ">\n",
    "> train=True -> whether this subset is train set.\n",
    ">\n",
    "> download=True -> ?\n",
    ">\n",
    "> transform = transforms.Compose([transforms.ToTensor()]) -> Transform data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\",train=True,download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\",train=False,download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adjust train set in to small batches and shuffle them.\n",
    "\n",
    "We want to train the whole dataset once, but its impossible. Instead, we train one batch a time. \n",
    "\n",
    "Model will find the shortest way to achieve goal, we need to shuffle the batch to let model know the question is not that easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train,batch_size=10,shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What is data in trainset looks like?\n",
    "\n",
    "Including two parts, image data and label data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([1, 1, 6, 1, 8, 9, 3, 4, 3, 0])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. View image and corresponding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0],data[1][0]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[0][0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View The size of the image. Notice there is a 1 dimension in the front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(data[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Percentage of each label\n",
    "\n",
    "Using a dictionary to count the number of each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs,ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "\n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
